Call us biased, but we believe we have the best TV reviews anywhere on the planet. Here 0027s how we do it.Yes, I0027m biased, but I consider CNET0027s TV reviews the best in the business. We0027ve come up with a set of tools and procedures designed to arrive at unbiased results by utilizing industry-accepted video-quality evaluation tools, objective testing criteria, and trained experts. The goal is to tell you what TVs are better than others, and why. Here0027s the complete guide to how we do it, updated in anticipation of 20130027s crop of new TVs .Test environment and equipmentOur main TV lab is a 1,200-square-foot room where we set up our comparison lineups. A curtain can divide the room in half so we can set up two different, independently light-controlled lineups at the same time. Light control is a big deal for TV testing. We have blackout shades we keep down (resulting in complete darkness) for most tests, but we can also raise them to evaluate a TV0027s bright-room performance. The walls are painted black, and the floor and ceiling are dark gray to minimize contamination from light and maximize background contrast.Here0027s a list of our other test equipment and hardware:Related storiesIt0027s worth noting that CNET obtains most of its review samples directly from manufacturers, typically by an editor asking a public relations representative for the desired model. This, unfortunately, can lead to manufacturers sending nonrepresentative samples, or even tampering with the units before they are sent, to help ensure more-positive reviews. If we spot a blatant case of tampering, we0027ll note it in the review, but we can0027t always prove it (and in case you0027re wondering, no, we0027ve never spotted a case of tampering that we could prove enough to mention in a review). If a manufacturer cannot ship us a sample or doesn0027t want us to review a particular set, we sometimes buy the model in question ourselves.TV makers generally group their models into series, which share identical features, styling, and specifications across multiple screen sizes. In 2009, CNET0027s TV reviews were expanded to cover other sizes in the series, not just the one size we typically review hands-on. While we don0027t test these other sizes directly, we feel that the performance-related remarks, as well as other portions of the review, apply closely enough to all sizes to warrant a \"series review\" approach. Even so, we are careful to check with the manufacturer to make sure there aren0027t any \"odd\" members of the series to which the review wouldn0027t apply. Check out our in-depth explanation for more .Test procedureWe strive to consistently test all TVs we review using the procedure below. In cases where not all of the tests are followed, we0027ll note the missing items in the review.Aside from the bright-room portion of the test (see below), all CNET HDTV reviews take place in a completely darkened environment. We realize that most people don0027t always watch TV in the dark, but we use a dark environment ourselves for a number of reasons. Most importantly, darkness eliminates the variable of light striking the TV0027s screen, which can skew the appearance of the image. It makes differences in image quality easier to spot, especially perceived black-level performance, which is severely affected by ambient light. Darkness also allows viewers at home to more easily match the experiences written about by the CNET reviewer. Finally, darkness is the environment we find most satisfying for watching high-quality material on a high-performance TV.Calibration Before we perform formal evaluations of HDTVs, we first calibrate their picture settings, with the help of the CalMAN software, to achieve peak performance in our dark room. Though it may seem more realistic to test TVs in the default picture settings, those settings often don0027t represent the TV0027s peak picture quality. Some are designed for maximum brightness, saturation, and impact on the showroom floor. That might sound desirable, but we believe a more natural, realistic picture looks better -- in other words, one that most accurately reproduces the incoming signal. Calibration also provides a level playing field for comparisons.Unlike some of the third-party TV calibrations offered today, the ones performed for CNET TV reviews do not utilize settings in the hidden \"service menus\" of televisions. Nearly all TVs have these menus, and previously we would access them to better calibrate our review samples. In the last few years, however, we have posted our ideal dark-room picture settings as part of our reviews, and since users cannot typically access those service menus (at least, not without voiding the warranty), we decided to no longer use them in our calibrations. We recommend that TV viewers avoid accessing the service menus themselves, because without proper training they can do more harm than good. Happily, many new HDTVs offer ample controls to achieve optimum picture quality without having to resort to service menus. Check out this QA for more.CNET TV calibrations follow a few steps, utilizing CalMAN 5 and patterns from the Quantum Data signal generator at 1080p/60 connected via HDMI to the TV.The results of the calibration are captured in a CalMAN report posted at the end of the review.All of our picture settings used to achieve the calibrated image are published on a post specific to each TV in CNET0027s picture settings forum. Each review contains a link and image (right) to that page. The picture settings are usually accompanied by detailed calibration notes as well as a link to the calibration report (see below). Users are free to reply and even submit their own picture settings. Here0027s an example.Side-by-side comparison Every HDTV CNET reviews is compared with others in the room during the evaluation. This is a direct, side-by-side comparison; the TVs are literally lined up next to one another and compared in real-time, with the reviewer recording observations on a laptop computer. We use numerous sources fed through a switch and a distribution amplifier -- a device that can feed multiple TVs the exact same signal with no degradation. TVs being compared often share similar price points, screen sizes, and other characteristics, but can just as often be more or less expensive or have different characteristics to better illustrate major differences (such as between LCD and plasma, or an extremely expensive set versus a less-expensive model).These comparisons allow CNET0027s to make definitive, in-context statements about virtually every area of a TV0027s performance, and their accuracy depends on each of the TVs sharing a level playing field. For that reason, we compare only calibrated televisions. We know of no other professional publication that regularly performs side-by-side comparisons as a part of nearly every review.Here are the main picture quality areas addressed in CNET reviews:In 2012, we also stopped testing TVs with PC sources since we saw little variation in how TVs handled digital (HDMI) video from computers, and analog (VGA) computer connections are less common. Check out How to use your TV as a computer monitor if you0027re interested in doing so.In early 2013, we began currently implementing new tests for projectors, as well as a test for input lag. See below for details.TV sound quality (by Ty Pendlebury) Due to reader demand , we began subjectively testing the quality of TVs0027 built-in audio in 2013. To test a TV we first set the sound mode to Standard or Flat at 50 percent volume and turn off modes like Surround or \"Enhanced Voice.\" If a TV has a specific music mode, we may test it at our discretion, but most importantly we want to test how clear dialogue is. We test the following three components:Input lag In June 2013 we began testing for input lag. Nearly every TVs introduces some amount of lag, measured in milliseconds, between receiving an input signal and displaying that signal on the screen. Relatively long lag times are anathema to skilled gamers who depend on split-second reactions, but those milliseconds otherwise have little effect on less-demanding games and non-gaming activities.Our test instrument for input lag is the Leo Bodnar lag tester (1080p version). We plug an HDMI cable from the tester directly into the TV0027s HDMI input, measure the lowest lag number reported for each of the three on-screen hashmarks the tester generates, and average the results. For TVs that won0027t generate a consistent number we trust, or won0027t display the signal at all, we won0027t report a result, and will describe the issue in the review.Currently we only report the lowest lag number the TV is capable of achieving in the test. Typically this is Game mode , which is typically designed to minimize lag. If the TV has a Game mode, we don0027t test any other settings for lag, because in our testing, Game had been invariably the mode with the lowest (best) lag number. If the TV lacks a Game mode, we test every picture preset, as well as the \"Calibrated\" picture, for lag, report the best result and indicate the mode in the Geek Box below.For more background on the test, check out Game mode on: CNET tests TVs for input lag .Geek Box and CalMAN reportThe box contains three columns: Test, Result and Score. Each test is detailed below. The result of each test is either numeric or pass/fail. Each score is either Good, Average or Poor. We determined the cutoffs for those scores based on guidelines in the CalMAN software (namely delta error levels), data gathered from past reviews and editorial discretion.Note that while these numbers and scores are useful, they don0027t necessarily represent the full picture quality of a display, and we consider many other factors when arriving at the numeric performance score in a CNET review.Unless otherwise noted, all test patterns measured are windows -- a rectangle of white, gray, or color in the center of the screen surrounded by black -- generated by the Quantum Data 780; all numbers reported are taken directly from CalMAN; \"error\" is Delta Error 2000 (dE2000) per CalMan; all percentages refer to test pattern0027s luminance, where 0 percent is black and 100 percent is white.Geek Box keyAvg. gamma (10-100%) Example result: 2.24 Gamma is a measure of how much light a display produces when fed a certain level of signal. The score is based on the result0027s +/- deviation from 2.2, the standard for professional video monitors. Good: less than 0.1 deviation Average: 0.2 or less deviation Poor: more than 0.2 deviationError tests and results After gamma, the next 11 tests report results as an \"error.\" Every result is reported as Delta Error 2000, where zero is perfect, and a lower number is better. The cutoffs for scores are based on targets within CalMAN 5, designed to represent human perception. Generally errors less than 3 are not perceptible. Good: 3 or less Average: 5 or less Poor: more than 5Avg. grayscale error (10-100%) An average of all 10 error results from 10 to 100% luminance grayscale windows. dE 2000 in this context (and for the next three tests) combines errors from gamma and the color of gray.Near-black error (5%) The color of gray at 5 percent luminance, slightly brighter than black. Near-black is often difficult to get correct.Dark gray error (20%) and Light gray error (70%) The color of gray at 20 percent and 70 percent luminance, the points at which we perform 2-point grayscale calibrations.Avg. color error The average of all six of the color error numbers below. Color errors in this context (and the next six tests) combine errors for luminance, saturation and hue.Red, Green, Blue, Cyan, Magenta, Yellow error The three primary and three secondary colors0027 errors, measured using a 75% luminance window.1080p/24 Cadence (IAL) (Pass/Fail) In this subjective test we look at our favorite test for proper film cadence, a helicopter flyover from the Blu-ray of \"I Am Legend\" (Chapter 7, 24:58 in) played back at 1080p/24 resolution. If the TV, in its most favorable setting, delivers the same look to the scene as our reference display, it passes. If it introduces smoothing or the hitching motion of 2:3 pull-down, it fails. Good: Proper film cadence (denoted by \"Pass\"). Poor: Improper film cadence (denoted by \"Fail\"). No average score possible1080i Deinterlacing (film) (Pass/Fail) We use the HQV Benchmark on Blu-ray0027s Film Resolution Loss Test to determine whether the display can recognize film-based content recorded at 24fps and convert it to the display0027s native resolution without losing detail. Good: Fine horizontal lines visible in corner boxes (denoted by \"Pass\") Poor: Boxes exhibit strobing and/or vertical bands (denoted by \"Fail\") No average score possible Motion resolution (max) and (dejudder off) We use the FPD Benchmark Software for Professional Blu-ray0027s moving Monoscope pattern to measure the maximum number of horizontal lines of resolution the display preserves during motion. Higher results are better. This test is often difficult to evaluate so it0027s subjective to a certain extent; we report the higher number in the range if in doubt. Check out our in-depth explanation for more. In the (max) row the TV is set to the most-favorable picture setting, while in the (dejudder off) row video processing that introduces smoothing is disabled to the largest extent possible. If such processing is impossible to turn off, we list a result of \"N/A.\" Good: 900 lines or more Average: 500 to 899 lines Poor: fewer than 500 lines Input lag (Game mode) Test procedure described above. Lower lag numbers are better. For TVs that lack a game mode, this row will indicate the picture preset mode, or \"Calibrated\" mode (referring to the lag when the TV is in its CNET-calibrated picture settings), whichever shows the lowest lag. Good: Less than 40 milliseconds Average: 40 to 70 milliseconds Poor: More than 70 millisecondsTV power consumption As of 2012, CNET no longer tests the power consumption of LED and LCD-based TVs 60 inches or smaller. The differences in energy use between them amount to only a few dollars per year. We will test larger LED and LCD TVs, however, as well as all sizes of plasma and OLED TVs.Home theater projectorsFirst and most obvious is the screen. Our test screen is a 120-inch diagonal, 16:9 Stewart StudioTek 130 G3, one of the highest-quality screens available. It0027s a high-gain screen that maintains excellent uniformity across its surface and is ideal for use in a dark room like ours.Since projectors generally aren0027t designed to produce as much light as standard TVs, we reduce our target light output during calibration from 40 fL (for TVs) to around 16 fL (for projectors). That luminance is the nominal value recommended by the Society of Motion Picture and Television Engineers (SMPTE) for cinema. The projected image is still plenty bright on our large screen in a dark room, and black levels are generally better than if we targeted a higher luminance.Unlike normal TV reviews, CNET does not publish picture settings for projectors. That0027s because screen sizes and materials vary significantly, so our settings on an identical projector with a different screen might not be correct. We omit audio testing with projectors, and add a section to our reviews that remarks upon setup-related issues. We also make sure to publish the projector0027s maximum light output.Section Editor David Katzmaier has reviewed TVs at CNET since 2002. He is an ISF certified, NIST trained calibrator and developed CNET0027s TV test procedure himself. Previously David wrote reviews and features for Sound  Vision magazine and eTown.com. See full bio